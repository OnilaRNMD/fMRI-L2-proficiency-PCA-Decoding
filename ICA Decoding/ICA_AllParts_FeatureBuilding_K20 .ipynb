{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c84d40",
   "metadata": {},
   "source": [
    "# ICA decoding — Part 1 (Feature building)\n",
    "This notebook mirrors your PCA Part 1, but uses ICA timecourses (`*_ICsK{K}.*`).\n",
    "\n",
    "**Run this first** to generate:\n",
    "- `features_static_nonZ_K20.csv`\n",
    "- `features_ln_conn_pearsonZ_K20.csv`\n",
    "- `features_delta_conn_pearsonZ_K20.csv`\n",
    "- `feature_build_manifest_K20.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bb057",
   "metadata": {},
   "source": [
    "## 0) Imports + settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce00742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built static feature table: (26, 120)\n",
      "Built Ln connectivity table: (26, 190)\n",
      "Built DELTA connectivity table: (26, 190)\n",
      "Missing L1/Ln pairs: 0\n",
      "Saved: /Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA/features_static_nonZ_K20.csv\n",
      "Saved: /Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA/features_ln_conn_pearsonZ_K20.csv\n",
      "Saved: /Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA/features_delta_conn_pearsonZ_K20.csv\n",
      "Saved: /Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA/feature_build_manifest_K20.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# PART 1 — ICA FEATURE BUILDING (UPDATED: saves Ln connectivity too)\n",
    "# Mirrors your PCA Part 1 exactly, but uses IC naming + file pattern *_ICsK{K}.*\n",
    "# =========================\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "# ---- USER SETTINGS ----\n",
    "ROOT = Path(r\"/Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA\")  # <-- CHANGE THIS IF NEEDED\n",
    "TC_DIR = ROOT / \"timecourses\"\n",
    "LABELS_CSV = ROOT / \"proficiency_labels.csv\"  # must exist in ROOT\n",
    "TASK_L1 = \"compL1\"\n",
    "TASK_LN = \"compLn\"\n",
    "K = 20                                   # <-- ICA K (change later for 5,10,15,25,30...)\n",
    "TR: Optional[float] = None               # set to TR (seconds) or keep None\n",
    "\n",
    "OUT_STATIC      = ROOT / f\"features_static_nonZ_K{K}.csv\"\n",
    "OUT_DELTA_CONN  = ROOT / f\"features_delta_conn_pearsonZ_K{K}.csv\"\n",
    "OUT_LN_CONN     = ROOT / f\"features_ln_conn_pearsonZ_K{K}.csv\"\n",
    "OUT_MANIFEST    = ROOT / f\"feature_build_manifest_K{K}.csv\"\n",
    "\n",
    "\n",
    "# ---- FILE DISCOVERY ----\n",
    "def discover_timecourses(tc_dir: Path, K: int):\n",
    "    \"\"\"\n",
    "    Finds ICA timecourse files like:\n",
    "      sub-01_task-compL1_ICsK20.npy  or  .csv\n",
    "    Returns dict: data[sub][task] = {\"npy\": path or None, \"csv\": path or None}\n",
    "    \"\"\"\n",
    "    patt = re.compile(r\"(sub-\\d+)_task-([A-Za-z0-9]+)_ICsK(\\d+)\\.(npy|csv)$\")\n",
    "    data = {}\n",
    "    for p in tc_dir.iterdir():\n",
    "        m = patt.match(p.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        sub, task, k_str, ext = m.group(1), m.group(2), m.group(3), m.group(4)\n",
    "        if int(k_str) != K:\n",
    "            continue\n",
    "        data.setdefault(sub, {}).setdefault(task, {\"npy\": None, \"csv\": None})\n",
    "        data[sub][task][ext] = p\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_tc(entry: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Prefer npy if present.\n",
    "    Returns X shape (T, K)\n",
    "    \"\"\"\n",
    "    if entry.get(\"npy\") is not None and entry[\"npy\"].exists():\n",
    "        X = np.load(entry[\"npy\"]).astype(np.float64)\n",
    "    elif entry.get(\"csv\") is not None and entry[\"csv\"].exists():\n",
    "        X = pd.read_csv(entry[\"csv\"]).values.astype(np.float64)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No npy/csv found for this entry.\")\n",
    "\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"Bad timecourse shape {X.shape}\")\n",
    "    return X\n",
    "\n",
    "\n",
    "# ---- FEATURE FUNCTIONS ----\n",
    "def lag1_autocorr(x: np.ndarray) -> float:\n",
    "    x0 = x[:-1]\n",
    "    x1 = x[1:]\n",
    "    s0 = x0.std()\n",
    "    s1 = x1.std()\n",
    "    if s0 == 0 or s1 == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x0, x1)[0, 1])\n",
    "\n",
    "\n",
    "def spectral_low_ratio(x: np.ndarray, tr: float, f_low=(0.01, 0.1)) -> float:\n",
    "    \"\"\"\n",
    "    Ratio of power in [0.01,0.1] Hz to total power (excluding DC).\n",
    "    Requires TR (seconds). If TR is None, we skip this feature.\n",
    "    \"\"\"\n",
    "    x = x - x.mean()\n",
    "    n = len(x)\n",
    "    freqs = np.fft.rfftfreq(n, d=tr)\n",
    "    Xf = np.fft.rfft(x)\n",
    "    psd = (np.abs(Xf) ** 2)\n",
    "\n",
    "    # exclude DC (0 Hz)\n",
    "    valid = freqs > 0\n",
    "    freqs = freqs[valid]\n",
    "    psd = psd[valid]\n",
    "    if psd.sum() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    band = (freqs >= f_low[0]) & (freqs <= f_low[1])\n",
    "    return float(psd[band].sum() / psd.sum())\n",
    "\n",
    "\n",
    "def per_ic_features(X: np.ndarray, prefix: str, tr: Optional[float]) -> dict:\n",
    "    \"\"\"\n",
    "    X: (T, K)\n",
    "    Per IC features that survive centering:\n",
    "      - logstd\n",
    "      - ac1\n",
    "      - lowRatio (optional if TR is provided)\n",
    "    \"\"\"\n",
    "    eps = 1e-12\n",
    "    feats = {}\n",
    "    for k in range(X.shape[1]):\n",
    "        ic = f\"IC{k+1:02d}\"\n",
    "        col = X[:, k]\n",
    "        std = col.std(ddof=0)\n",
    "        feats[f\"{prefix}_{ic}_logstd\"] = float(np.log(std + eps))\n",
    "        feats[f\"{prefix}_{ic}_ac1\"] = lag1_autocorr(col)\n",
    "        if tr is not None:\n",
    "            feats[f\"{prefix}_{ic}_lowRatio\"] = spectral_low_ratio(col, tr=tr)\n",
    "    return feats\n",
    "\n",
    "\n",
    "def fisher_z_corr(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pearson correlation matrix -> Fisher z transform, clipped.\n",
    "    \"\"\"\n",
    "    C = np.corrcoef(X, rowvar=False)\n",
    "    np.fill_diagonal(C, 0.0)\n",
    "    C = np.clip(C, -0.999999, 0.999999)\n",
    "    Z = np.arctanh(C)\n",
    "    np.fill_diagonal(Z, 0.0)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def upper_triangle_features(M: np.ndarray, prefix: str) -> dict:\n",
    "    \"\"\"\n",
    "    Flatten upper triangle (i<j) into named features.\n",
    "    \"\"\"\n",
    "    K = M.shape[0]\n",
    "    feats = {}\n",
    "    for i in range(K):\n",
    "        for j in range(i + 1, K):\n",
    "            feats[f\"{prefix}_IC{i+1:02d}_IC{j+1:02d}\"] = float(M[i, j])\n",
    "    return feats\n",
    "\n",
    "\n",
    "# ---- BUILD FEATURE TABLES ----\n",
    "tc_index = discover_timecourses(TC_DIR, K=K)\n",
    "subjects = sorted(tc_index.keys())\n",
    "\n",
    "rows_static = []\n",
    "rows_conn_delta = []\n",
    "rows_conn_ln = []          # Ln connectivity\n",
    "manifest_rows = []\n",
    "missing_pairs = 0\n",
    "\n",
    "for sub in subjects:\n",
    "    if TASK_L1 not in tc_index[sub] or TASK_LN not in tc_index[sub]:\n",
    "        missing_pairs += 1\n",
    "        continue\n",
    "\n",
    "    X1 = load_tc(tc_index[sub][TASK_L1])\n",
    "    X2 = load_tc(tc_index[sub][TASK_LN])\n",
    "\n",
    "    if X1.shape[1] != K or X2.shape[1] != K:\n",
    "        raise ValueError(f\"{sub} wrong K: {X1.shape}, {X2.shape}\")\n",
    "\n",
    "    # static features per task\n",
    "    f1 = per_ic_features(X1, \"L1\", tr=TR)\n",
    "    f2 = per_ic_features(X2, \"Ln\", tr=TR)\n",
    "\n",
    "    # delta features (Ln - L1) for each feature\n",
    "    delta = {}\n",
    "    for key, v in f1.items():\n",
    "        ln_key = key.replace(\"L1_\", \"Ln_\")\n",
    "        delta[key.replace(\"L1_\", \"DELTA_\")] = f2[ln_key] - v\n",
    "\n",
    "    row = {\"subject\": sub}\n",
    "    row.update(f1)\n",
    "    row.update(f2)\n",
    "    row.update(delta)\n",
    "    rows_static.append(row)\n",
    "\n",
    "    # connectivity: Ln, L1, and DELTA\n",
    "    Z1 = fisher_z_corr(X1)\n",
    "    Z2 = fisher_z_corr(X2)\n",
    "    ZD = Z2 - Z1\n",
    "\n",
    "    row_ln = {\"subject\": sub}\n",
    "    row_ln.update(upper_triangle_features(Z2, prefix=\"Ln_zcorr\"))\n",
    "    rows_conn_ln.append(row_ln)\n",
    "\n",
    "    rowd = {\"subject\": sub}\n",
    "    rowd.update(upper_triangle_features(ZD, prefix=\"DELTA_zcorr\"))\n",
    "    rows_conn_delta.append(rowd)\n",
    "\n",
    "    manifest_rows.append({\n",
    "        \"subject\": sub,\n",
    "        \"T_L1\": X1.shape[0],\n",
    "        \"T_Ln\": X2.shape[0],\n",
    "        \"has_TR_features\": TR is not None\n",
    "    })\n",
    "\n",
    "static_df = pd.DataFrame(rows_static).set_index(\"subject\").sort_index()\n",
    "ln_conn_df = pd.DataFrame(rows_conn_ln).set_index(\"subject\").sort_index()\n",
    "delta_conn_df = pd.DataFrame(rows_conn_delta).set_index(\"subject\").sort_index()\n",
    "manifest_df = pd.DataFrame(manifest_rows)\n",
    "\n",
    "print(\"Built static feature table:\", static_df.shape)\n",
    "print(\"Built Ln connectivity table:\", ln_conn_df.shape)\n",
    "print(\"Built DELTA connectivity table:\", delta_conn_df.shape)\n",
    "print(\"Missing L1/Ln pairs:\", missing_pairs)\n",
    "\n",
    "static_df.to_csv(OUT_STATIC)\n",
    "ln_conn_df.to_csv(OUT_LN_CONN)\n",
    "delta_conn_df.to_csv(OUT_DELTA_CONN)\n",
    "manifest_df.to_csv(OUT_MANIFEST, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_STATIC)\n",
    "print(\"Saved:\", OUT_LN_CONN)\n",
    "print(\"Saved:\", OUT_DELTA_CONN)\n",
    "print(\"Saved:\", OUT_MANIFEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb15667-eab0-4995-928a-e396a6881e60",
   "metadata": {},
   "source": [
    "# ICA decoding — Part 2 (Modeling + validation)\n",
    "This mirrors your PCA Part 2, using the ICA feature files created in Part 1.\n",
    "\n",
    "It prints results for:\n",
    "- **L1-only**\n",
    "- **Ln-only**\n",
    "- **Delta-only (Ln−L1)**\n",
    "- **Full (L1+Ln+Delta)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db627de-bd13-41a5-8ed0-6ff078029852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N aligned: 26 class counts: {'advanced': 15, 'intermediate': 11}\n",
      "Shapes: L1 (26, 40) Ln (26, 40) Delta (26, 40) Full (26, 120)\n",
      "\n",
      "====== L1-only (negative control) ======\n",
      "LOOCV AUC: 0.6424242424242423 Bootstrap 95% CI: (0.4106894841269841, 0.8472222222222222)\n",
      "RepCV AUC mean±sd: 0.6247222222222223 0.25350003652567493\n",
      "RepCV BAL mean±sd: 0.5929166666666666 0.20992351451051033\n",
      "Nested (tune C/penalty only) outer AUC mean±sd: 0.5371111111111111 0.2476916641589441\n",
      "Top hyperparams: [(('l1', 1), 47), (('l2', 0.001), 33), (('l1', 10), 30), (('l2', 1), 29), (('l1', 1000), 25)]\n",
      "Permutation (5-fold) AUC score: 0.6444444444444443 p-value: 0.25487256371814093\n",
      "\n",
      "====== Ln-only ======\n",
      "LOOCV AUC: 0.6181818181818182 Bootstrap 95% CI: (0.38181818181818183, 0.8273809523809524)\n",
      "RepCV AUC mean±sd: 0.6105 0.25390091753659716\n",
      "RepCV BAL mean±sd: 0.5514166666666667 0.20639617715559666\n",
      "Nested (tune C/penalty only) outer AUC mean±sd: 0.5668888888888889 0.24642119918425728\n",
      "Top hyperparams: [(('l2', 0.001), 132), (('l2', 1), 23), (('l2', 0.1), 21), (('l2', 0.01), 15), (('l1', 0.001), 12)]\n",
      "Permutation (5-fold) AUC score: 0.711111111111111 p-value: 0.12993503248375812\n",
      "\n",
      "====== Delta-only ======\n",
      "LOOCV AUC: 0.6484848484848486 Bootstrap 95% CI: (0.41829768270944745, 0.8545454545454545)\n",
      "RepCV AUC mean±sd: 0.6818888888888889 0.22657489972453962\n",
      "RepCV BAL mean±sd: 0.70125 0.19240392624199054\n",
      "Nested (tune C/penalty only) outer AUC mean±sd: 0.6846666666666668 0.2261529035906219\n",
      "Top hyperparams: [(('l2', 0.001), 137), (('l2', 1), 23), (('l2', 0.1), 18), (('l2', 0.01), 16), (('l2', 10), 15)]\n",
      "Permutation (5-fold) AUC score: 0.6666666666666666 p-value: 0.17041479260369816\n",
      "\n",
      "====== FULL (L1+Ln+Delta) ======\n",
      "LOOCV AUC: 0.6363636363636364 Bootstrap 95% CI: (0.39869281045751637, 0.849624060150376)\n",
      "RepCV AUC mean±sd: 0.6455 0.24666816190738\n",
      "RepCV BAL mean±sd: 0.588 0.1930541087076079\n",
      "Nested (tune C/penalty only) outer AUC mean±sd: 0.5988888888888889 0.23781152408505\n",
      "Top hyperparams: [(('l2', 0.001), 107), (('l2', 0.1), 32), (('l2', 1), 27), (('l2', 0.01), 17), (('l2', 10), 17)]\n",
      "Permutation (5-fold) AUC score: 0.788888888888889 p-value: 0.041979010494752625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# PART 2 — ICA MODELING + VALIDATION\n",
    "# Mirrors your PCA Part 2 exactly, but uses ICA feature files (IC-based names).\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    LeaveOneOut,\n",
    "    RepeatedStratifiedKFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_predict,\n",
    "    permutation_test_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "ROOT = Path(r\"/Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA\")  # <-- SAME AS PART 1\n",
    "LABELS_CSV = ROOT / \"proficiency_labels.csv\"\n",
    "K = 20\n",
    "\n",
    "FEAT_STATIC = ROOT / f\"features_static_nonZ_K{K}.csv\"\n",
    "FEAT_LN_CONN = ROOT / f\"features_ln_conn_pearsonZ_K{K}.csv\"   # used in Part 3\n",
    "FEAT_DELTA_CONN = ROOT / f\"features_delta_conn_pearsonZ_K{K}.csv\"\n",
    "\n",
    "labels = pd.read_csv(LABELS_CSV).set_index(\"subject\")\n",
    "labels[\"group\"] = labels[\"group\"].str.lower().str.strip()\n",
    "labels[\"y\"] = (labels[\"group\"] == \"advanced\").astype(int)\n",
    "\n",
    "Xstatic = pd.read_csv(FEAT_STATIC).set_index(\"subject\")\n",
    "\n",
    "df = Xstatic.join(labels[[\"y\"]], how=\"inner\")\n",
    "y = df[\"y\"].to_numpy()\n",
    "\n",
    "X_L1    = df.filter(regex=r\"^L1_\").copy()\n",
    "X_Ln    = df.filter(regex=r\"^Ln_\").copy()\n",
    "X_Delta = df.filter(regex=r\"^DELTA_\").copy()\n",
    "X_Full  = df.drop(columns=[\"y\"]).copy()\n",
    "\n",
    "print(\"N aligned:\", df.shape[0], \"class counts:\", labels[\"group\"].value_counts().to_dict())\n",
    "print(\"Shapes:\", \"L1\", X_L1.shape, \"Ln\", X_Ln.shape, \"Delta\", X_Delta.shape, \"Full\", X_Full.shape)\n",
    "\n",
    "def fixed_pipeline(C=1.0, penalty=\"l2\"):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=5000,\n",
    "            C=C,\n",
    "            penalty=penalty\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def loocv_auc_with_bootstrap_ci(Xdf, y, pipe, n_boot=5000, seed=0):\n",
    "    loo = LeaveOneOut()\n",
    "    prob = cross_val_predict(pipe, Xdf, y, cv=loo, method=\"predict_proba\")[:, 1]\n",
    "    auc = roc_auc_score(y, prob)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(y))\n",
    "    boots = []\n",
    "    for _ in range(n_boot):\n",
    "        samp = rng.choice(idx, size=len(idx), replace=True)\n",
    "        if len(np.unique(y[samp])) < 2:\n",
    "            continue\n",
    "        boots.append(roc_auc_score(y[samp], prob[samp]))\n",
    "    boots = np.array(boots)\n",
    "    ci_lo, ci_hi = np.quantile(boots, [0.025, 0.975])\n",
    "    return float(auc), (float(ci_lo), float(ci_hi))\n",
    "\n",
    "def repeated_cv_auc_dist(Xdf, y, pipe, n_splits=5, n_repeats=200, seed=42):\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    aucs, bals = [], []\n",
    "    for tr, te in rskf.split(Xdf, y):\n",
    "        pipe.fit(Xdf.iloc[tr], y[tr])\n",
    "        p = pipe.predict_proba(Xdf.iloc[te])[:, 1]\n",
    "        pred = (p >= 0.5).astype(int)\n",
    "        aucs.append(roc_auc_score(y[te], p))\n",
    "        bals.append(balanced_accuracy_score(y[te], pred))\n",
    "    return np.array(aucs), np.array(bals)\n",
    "\n",
    "def minimal_nested_tuning(Xdf, y,\n",
    "                         C_grid=(0.001, 0.01, 0.1, 1, 10, 100, 1000),\n",
    "                         penalty_grid=(\"l2\", \"l1\"),\n",
    "                         outer_splits=5, outer_repeats=100, inner_splits=5, seed=42):\n",
    "    outer = RepeatedStratifiedKFold(n_splits=outer_splits, n_repeats=outer_repeats, random_state=seed)\n",
    "    inner = StratifiedKFold(n_splits=inner_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    chosen = []\n",
    "    outer_auc = []\n",
    "\n",
    "    for tr, te in outer.split(Xdf, y):\n",
    "        X_tr, X_te = Xdf.iloc[tr], Xdf.iloc[te]\n",
    "        y_tr, y_te = y[tr], y[te]\n",
    "\n",
    "        best_auc = -np.inf\n",
    "        best_hp = None\n",
    "\n",
    "        for pen in penalty_grid:\n",
    "            for C in C_grid:\n",
    "                pipe = fixed_pipeline(C=C, penalty=pen)\n",
    "                inner_aucs = []\n",
    "                for tr2, te2 in inner.split(X_tr, y_tr):\n",
    "                    pipe.fit(X_tr.iloc[tr2], y_tr[tr2])\n",
    "                    p = pipe.predict_proba(X_tr.iloc[te2])[:, 1]\n",
    "                    inner_aucs.append(roc_auc_score(y_tr[te2], p))\n",
    "                m = float(np.mean(inner_aucs))\n",
    "                if m > best_auc:\n",
    "                    best_auc, best_hp = m, (pen, C)\n",
    "\n",
    "        pen, C = best_hp\n",
    "        pipe = fixed_pipeline(C=C, penalty=pen)\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        p = pipe.predict_proba(X_te)[:, 1]\n",
    "        outer_auc.append(float(roc_auc_score(y_te, p)))\n",
    "        chosen.append(best_hp)\n",
    "\n",
    "    from collections import Counter\n",
    "    counts = Counter(chosen)\n",
    "    return float(np.mean(outer_auc)), float(np.std(outer_auc)), counts\n",
    "\n",
    "def fast_permutation_pvalue(Xdf, y, pipe, n_perm=2000, seed=0):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    score, perm_scores, pvalue = permutation_test_score(\n",
    "        pipe, Xdf, y,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=cv,\n",
    "        n_permutations=n_perm,\n",
    "        n_jobs=-1,\n",
    "        random_state=seed\n",
    "    )\n",
    "    return float(score), float(pvalue)\n",
    "\n",
    "def run_bundle(name, Xdf):\n",
    "    print(\"\\n======\", name, \"======\")\n",
    "    pipe = fixed_pipeline(C=1.0, penalty=\"l2\")\n",
    "\n",
    "    auc_loocv, ci = loocv_auc_with_bootstrap_ci(Xdf, y, pipe, n_boot=5000, seed=0)\n",
    "    print(\"LOOCV AUC:\", auc_loocv, \"Bootstrap 95% CI:\", ci)\n",
    "\n",
    "    aucs, bals = repeated_cv_auc_dist(Xdf, y, pipe, n_splits=5, n_repeats=200, seed=42)\n",
    "    print(\"RepCV AUC mean±sd:\", float(aucs.mean()), float(aucs.std()))\n",
    "    print(\"RepCV BAL mean±sd:\", float(bals.mean()), float(bals.std()))\n",
    "\n",
    "    outer_mean, outer_sd, counts = minimal_nested_tuning(Xdf, y, outer_repeats=50)\n",
    "    print(\"Nested (tune C/penalty only) outer AUC mean±sd:\", outer_mean, outer_sd)\n",
    "    print(\"Top hyperparams:\", counts.most_common(5))\n",
    "\n",
    "    score, pval = fast_permutation_pvalue(Xdf, y, pipe, n_perm=2000, seed=0)\n",
    "    print(\"Permutation (5-fold) AUC score:\", score, \"p-value:\", pval)\n",
    "\n",
    "# Run models\n",
    "run_bundle(\"L1-only (negative control)\", X_L1)\n",
    "run_bundle(\"Ln-only\", X_Ln)\n",
    "run_bundle(\"Delta-only\", X_Delta)\n",
    "run_bundle(\"FULL (L1+Ln+Delta)\", X_Full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4af76-85ff-499f-8f5a-4e5d4c2f4470",
   "metadata": {},
   "source": [
    "# ICA decoding — Part 3 (Ln-only + top-IC Ln connectivity)\n",
    "This mirrors your PCA Part 3 exactly:\n",
    "1) Train Ln-only model on TRAIN folds\n",
    "2) Pick **top 5 ICs** from TRAIN-only weights\n",
    "3) Add Ln connectivity edges among those 5 ICs\n",
    "4) Evaluate with repeated CV + **manual permutation test** (leakage-safe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee94ab8-6aaa-4a18-970d-ca237e248440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated CV summary (sanity-checked): Ln-only base + top-IC Ln connectivity ===\n",
      "[OK] Found 190 connectivity columns with prefix 'Ln_zcorr'.\n",
      "[INFO] top_m=7 -> expected edges per fold = C(7,2) = 21\n",
      "[INFO] Avg missing edges per fold: 0.000 (should be ~0)\n",
      "{'auc_mean': 0.7136666666666668, 'auc_sd': 0.24949507033898843, 'n_folds': 1000, 'most_common_ic_sets': [((7, 19, 12, 9, 15, 8, 1), 2), ((1, 5, 19, 12, 6, 7, 10), 2), ((2, 1, 8, 12, 19, 18, 16), 2), ((6, 7, 20, 16, 18, 8, 13), 2), ((7, 19, 9, 15, 20, 8, 5), 2), ((19, 15, 5, 6, 18, 14, 16), 2), ((19, 9, 1, 12, 2, 16, 14), 2), ((1, 19, 2, 15, 9, 12, 18), 2), ((7, 6, 16, 8, 20, 18, 13), 2), ((7, 19, 18, 5, 17, 6, 8), 2)], 'most_used_edges': [('Ln_zcorr_IC06_IC19', 673), ('Ln_zcorr_IC07_IC19', 559), ('Ln_zcorr_IC18_IC19', 551), ('Ln_zcorr_IC15_IC19', 540), ('Ln_zcorr_IC12_IC19', 535), ('Ln_zcorr_IC06_IC07', 486), ('Ln_zcorr_IC06_IC18', 463), ('Ln_zcorr_IC05_IC19', 433), ('Ln_zcorr_IC06_IC15', 413), ('Ln_zcorr_IC09_IC19', 391), ('Ln_zcorr_IC08_IC19', 378), ('Ln_zcorr_IC06_IC12', 375), ('Ln_zcorr_IC07_IC18', 374), ('Ln_zcorr_IC12_IC15', 352), ('Ln_zcorr_IC05_IC06', 350)], 'avg_missing_edges_per_fold': 0.0, 'top_m': 7, 'expected_edges_per_fold': 21}\n",
      "\n",
      "=== Manual permutation test (leakage-safe) for augmented Ln model ===\n",
      "[OK] Found 190 connectivity columns with prefix 'Ln_zcorr'.\n",
      "[perm] 200/2000 done...\n",
      "[perm] 400/2000 done...\n",
      "[perm] 600/2000 done...\n",
      "[perm] 800/2000 done...\n",
      "[perm] 1000/2000 done...\n",
      "[perm] 1200/2000 done...\n",
      "[perm] 1400/2000 done...\n",
      "[perm] 1600/2000 done...\n",
      "[perm] 1800/2000 done...\n",
      "[perm] 2000/2000 done...\n",
      "Observed 5-fold AUC: 0.8555555555555555\n",
      "Permutation p-value: 0.015992003998001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# PART 3 — LN-ONLY + TOP-IC LN CONNECTIVITY (LEAKAGE-SAFE)\n",
    "# + Manual permutation test (publication-friendly; avoids sklearn tag issues)\n",
    "# Mirrors your PCA Part 3, but uses IC naming.\n",
    "# =========================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Basic model builder\n",
    "# -------------------------\n",
    "def fixed_pipe(C=1.0, penalty=\"l2\"):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=5000,\n",
    "            C=C,\n",
    "            penalty=penalty\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "def ic_group_importance_from_coef(feature_names, coef):\n",
    "    \"\"\"Sum |coef| by IC index extracted from names like Ln_IC07_...\"\"\"\n",
    "    ic_re = re.compile(r\"IC(\\d{2})\")\n",
    "    scores = {}\n",
    "    for name, w in zip(feature_names, coef):\n",
    "        m = ic_re.search(name)\n",
    "        if not m:\n",
    "            continue\n",
    "        ic = int(m.group(1))\n",
    "        scores[ic] = scores.get(ic, 0.0) + abs(float(w))\n",
    "    return scores\n",
    "\n",
    "def connectivity_cols_for_ics(ics, prefix=\"Ln_zcorr\"):\n",
    "    ics = sorted(ics)\n",
    "    cols = []\n",
    "    for i in range(len(ics)):\n",
    "        for j in range(i + 1, len(ics)):\n",
    "            a, b = ics[i], ics[j]\n",
    "            cols.append(f\"{prefix}_IC{a:02d}_IC{b:02d}\")\n",
    "    return cols\n",
    "\n",
    "def sanity_check_inputs(Xbase: pd.DataFrame, conn: pd.DataFrame, y: np.ndarray, conn_prefix: str):\n",
    "    assert isinstance(Xbase, pd.DataFrame) and isinstance(conn, pd.DataFrame)\n",
    "    assert len(Xbase) == len(y), \"Xbase and y length mismatch\"\n",
    "    assert Xbase.index.equals(conn.index), \"Xbase and conn indices must match exactly\"\n",
    "    assert set(np.unique(y)).issubset({0, 1}), \"y must be binary 0/1\"\n",
    "\n",
    "    pref_cols = [c for c in conn.columns if c.startswith(conn_prefix + \"_IC\")]\n",
    "    if len(pref_cols) == 0:\n",
    "        raise ValueError(f\"No connectivity columns found with prefix='{conn_prefix}'.\")\n",
    "    print(f\"[OK] Found {len(pref_cols)} connectivity columns with prefix '{conn_prefix}'.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Core: single CV run (supports either real y or permuted y)\n",
    "# -------------------------\n",
    "def cv_auc_foldwise_augmented(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    splits,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    return_debug: bool = False\n",
    "):\n",
    "    aucs = []\n",
    "    picked_sets = []\n",
    "    edge_use_counter = Counter()\n",
    "    missing_edges_total = 0\n",
    "\n",
    "    for tr, te in splits:\n",
    "        Xtr, Xte = Xbase.iloc[tr], Xbase.iloc[te]\n",
    "        ytr, yte = y[tr], y[te]\n",
    "\n",
    "        # 1) pick top ICs from TRAIN only (Ln-only)\n",
    "        base_model = fixed_pipe(C=C_base, penalty=penalty)\n",
    "        base_model.fit(Xtr, ytr)\n",
    "        w = base_model.named_steps[\"clf\"].coef_.ravel()\n",
    "        scores = ic_group_importance_from_coef(Xtr.columns, w)\n",
    "        top = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)[:top_m]\n",
    "        top_ics = [ic for ic, _ in top]\n",
    "        picked_sets.append(tuple(top_ics))\n",
    "\n",
    "        # 2) add connectivity edges among those ICs\n",
    "        wanted_cols = connectivity_cols_for_ics(top_ics, prefix=conn_prefix)\n",
    "        cols = [c for c in wanted_cols if c in conn.columns]\n",
    "        missing_edges_total += (len(wanted_cols) - len(cols))\n",
    "        edge_use_counter.update(cols)\n",
    "\n",
    "        Xtr_aug = pd.concat([Xtr, conn.iloc[tr][cols]], axis=1)\n",
    "        Xte_aug = pd.concat([Xte, conn.iloc[te][cols]], axis=1)\n",
    "\n",
    "        # 3) fit final model and score AUC\n",
    "        final_model = fixed_pipe(C=C_final, penalty=penalty)\n",
    "        final_model.fit(Xtr_aug, ytr)\n",
    "        p = final_model.predict_proba(Xte_aug)[:, 1]\n",
    "\n",
    "        # If test fold has only one class, AUC undefined -> skip fold\n",
    "        if len(np.unique(yte)) < 2:\n",
    "            continue\n",
    "\n",
    "        aucs.append(roc_auc_score(yte, p))\n",
    "\n",
    "    auc_mean = float(np.mean(aucs))\n",
    "\n",
    "    if not return_debug:\n",
    "        return auc_mean\n",
    "\n",
    "    n_folds = len(aucs)\n",
    "    return {\n",
    "        \"auc_mean\": auc_mean,\n",
    "        \"auc_sd\": float(np.std(aucs)),\n",
    "        \"n_folds\": int(n_folds),\n",
    "        \"most_common_ic_sets\": Counter(picked_sets).most_common(10),\n",
    "        \"most_used_edges\": edge_use_counter.most_common(15),\n",
    "        \"avg_missing_edges_per_fold\": float(missing_edges_total / n_folds) if n_folds > 0 else float(\"nan\")\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Repeated CV summary\n",
    "# -------------------------\n",
    "def repeated_cv_summary_augmented(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    n_splits: int = 5,\n",
    "    n_repeats: int = 200,\n",
    "    seed: int = 42\n",
    "):\n",
    "    sanity_check_inputs(Xbase, conn, y, conn_prefix=conn_prefix)\n",
    "    expected_edges = top_m * (top_m - 1) // 2\n",
    "    print(f\"[INFO] top_m={top_m} -> expected edges per fold = C({top_m},2) = {expected_edges}\")\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    splits = list(rskf.split(Xbase, y))\n",
    "\n",
    "    out = cv_auc_foldwise_augmented(\n",
    "        Xbase, conn, y, splits,\n",
    "        conn_prefix=conn_prefix,\n",
    "        top_m=top_m,\n",
    "        C_base=C_base,\n",
    "        C_final=C_final,\n",
    "        penalty=penalty,\n",
    "        return_debug=True\n",
    "    )\n",
    "\n",
    "    print(f\"[INFO] Avg missing edges per fold: {out['avg_missing_edges_per_fold']:.3f} (should be ~0)\")\n",
    "    out[\"top_m\"] = int(top_m)\n",
    "    out[\"expected_edges_per_fold\"] = int(expected_edges)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Manual permutation test (publication-friendly)\n",
    "# -------------------------\n",
    "def permutation_test_augmented_auc(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    n_splits: int = 5,\n",
    "    n_perm: int = 2000,\n",
    "    seed: int = 0,\n",
    "    verbose_every: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      observed_auc, p_value, perm_aucs (array)\n",
    "    p-value computed as (1 + #perm >= obs) / (1 + n_perm)\n",
    "    \"\"\"\n",
    "    sanity_check_inputs(Xbase, conn, y, conn_prefix=conn_prefix)\n",
    "\n",
    "    # Fix CV splits once (important!)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    splits = list(cv.split(Xbase, y))\n",
    "\n",
    "    # Observed score\n",
    "    obs = cv_auc_foldwise_augmented(\n",
    "        Xbase, conn, y, splits,\n",
    "        conn_prefix=conn_prefix,\n",
    "        top_m=top_m,\n",
    "        C_base=C_base,\n",
    "        C_final=C_final,\n",
    "        penalty=penalty,\n",
    "        return_debug=False\n",
    "    )\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm_scores = np.empty(n_perm, dtype=float)\n",
    "\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y)  # preserves class counts automatically\n",
    "        perm_scores[i] = cv_auc_foldwise_augmented(\n",
    "            Xbase, conn, y_perm, splits,\n",
    "            conn_prefix=conn_prefix,\n",
    "            top_m=top_m,\n",
    "            C_base=C_base,\n",
    "            C_final=C_final,\n",
    "            penalty=penalty,\n",
    "            return_debug=False\n",
    "        )\n",
    "        if verbose_every and (i + 1) % verbose_every == 0:\n",
    "            print(f\"[perm] {i+1}/{n_perm} done...\")\n",
    "\n",
    "    p = (1.0 + np.sum(perm_scores >= obs)) / (1.0 + n_perm)\n",
    "    return float(obs), float(p), perm_scores\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# RUN (Ln-only + Ln connectivity)\n",
    "# -------------------------\n",
    "ROOT = Path(r\"/Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA\")\n",
    "K = 20\n",
    "\n",
    "LABELS_CSV = ROOT / \"proficiency_labels.csv\"\n",
    "FEAT_STATIC = ROOT / f\"features_static_nonZ_K{K}.csv\"\n",
    "FEAT_LN_CONN = ROOT / f\"features_ln_conn_pearsonZ_K{K}.csv\"\n",
    "\n",
    "labels = pd.read_csv(LABELS_CSV).set_index(\"subject\")\n",
    "labels[\"group\"] = labels[\"group\"].str.lower().str.strip()\n",
    "labels[\"y\"] = (labels[\"group\"] == \"advanced\").astype(int)\n",
    "\n",
    "Xstatic = pd.read_csv(FEAT_STATIC).set_index(\"subject\")\n",
    "connLn = pd.read_csv(FEAT_LN_CONN).set_index(\"subject\")\n",
    "\n",
    "df = Xstatic.join(labels[[\"y\"]], how=\"inner\")\n",
    "X_Ln = df.filter(regex=r\"^Ln_\").copy()\n",
    "\n",
    "# Align (exact index match)\n",
    "common = X_Ln.index.intersection(connLn.index)\n",
    "X_base = X_Ln.loc[common].copy()\n",
    "y_base = labels.loc[common, \"y\"].to_numpy()\n",
    "connLn = connLn.loc[common].copy()\n",
    "connLn = connLn.loc[X_base.index]\n",
    "\n",
    "print(\"\\n=== Repeated CV summary (sanity-checked): Ln-only base + top-IC Ln connectivity ===\")\n",
    "aug_ln = repeated_cv_summary_augmented(\n",
    "    Xbase=X_base,\n",
    "    conn=connLn,\n",
    "    y=y_base,\n",
    "    conn_prefix=\"Ln_zcorr\",\n",
    "    top_m=7,\n",
    "    C_base=1.0,\n",
    "    C_final=1.0,\n",
    "    penalty=\"l2\",\n",
    "    n_splits=5,\n",
    "    n_repeats=200,\n",
    "    seed=42\n",
    ")\n",
    "print(aug_ln)\n",
    "\n",
    "print(\"\\n=== Manual permutation test (leakage-safe) for augmented Ln model ===\")\n",
    "obs_auc, pval, perm_aucs = permutation_test_augmented_auc(\n",
    "    Xbase=X_base,\n",
    "    conn=connLn,\n",
    "    y=y_base,\n",
    "    conn_prefix=\"Ln_zcorr\",\n",
    "    top_m=7,\n",
    "    C_base=1.0,\n",
    "    C_final=1.0,\n",
    "    penalty=\"l2\",\n",
    "    n_splits=5,\n",
    "    n_perm=2000,     # start 500 if you want quick; 2000 for final\n",
    "    seed=0,\n",
    "    verbose_every=200\n",
    ")\n",
    "print(\"Observed 5-fold AUC:\", obs_auc)\n",
    "print(\"Permutation p-value:\", pval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e3f4b-6ac9-4e7d-92e4-076bd12f18d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
