{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960d00d4",
   "metadata": {},
   "source": [
    "# ICA decoding — Part 3 (Ln-only + top-IC Ln connectivity)\n",
    "This mirrors your PCA Part 3 exactly:\n",
    "1) Train Ln-only model on TRAIN folds\n",
    "2) Pick **top 5 ICs** from TRAIN-only weights\n",
    "3) Add Ln connectivity edges among those 5 ICs\n",
    "4) Evaluate with repeated CV + **manual permutation test** (leakage-safe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cdb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# PART 3 — LN-ONLY + TOP-IC LN CONNECTIVITY (LEAKAGE-SAFE)\n",
    "# + Manual permutation test (publication-friendly; avoids sklearn tag issues)\n",
    "# Mirrors your PCA Part 3, but uses IC naming.\n",
    "# =========================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Basic model builder\n",
    "# -------------------------\n",
    "def fixed_pipe(C=1.0, penalty=\"l2\"):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=5000,\n",
    "            C=C,\n",
    "            penalty=penalty\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "def ic_group_importance_from_coef(feature_names, coef):\n",
    "    \"\"\"Sum |coef| by IC index extracted from names like Ln_IC07_...\"\"\"\n",
    "    ic_re = re.compile(r\"IC(\\d{2})\")\n",
    "    scores = {}\n",
    "    for name, w in zip(feature_names, coef):\n",
    "        m = ic_re.search(name)\n",
    "        if not m:\n",
    "            continue\n",
    "        ic = int(m.group(1))\n",
    "        scores[ic] = scores.get(ic, 0.0) + abs(float(w))\n",
    "    return scores\n",
    "\n",
    "def connectivity_cols_for_ics(ics, prefix=\"Ln_zcorr\"):\n",
    "    ics = sorted(ics)\n",
    "    cols = []\n",
    "    for i in range(len(ics)):\n",
    "        for j in range(i + 1, len(ics)):\n",
    "            a, b = ics[i], ics[j]\n",
    "            cols.append(f\"{prefix}_IC{a:02d}_IC{b:02d}\")\n",
    "    return cols\n",
    "\n",
    "def sanity_check_inputs(Xbase: pd.DataFrame, conn: pd.DataFrame, y: np.ndarray, conn_prefix: str):\n",
    "    assert isinstance(Xbase, pd.DataFrame) and isinstance(conn, pd.DataFrame)\n",
    "    assert len(Xbase) == len(y), \"Xbase and y length mismatch\"\n",
    "    assert Xbase.index.equals(conn.index), \"Xbase and conn indices must match exactly\"\n",
    "    assert set(np.unique(y)).issubset({0, 1}), \"y must be binary 0/1\"\n",
    "\n",
    "    pref_cols = [c for c in conn.columns if c.startswith(conn_prefix + \"_IC\")]\n",
    "    if len(pref_cols) == 0:\n",
    "        raise ValueError(f\"No connectivity columns found with prefix='{conn_prefix}'.\")\n",
    "    print(f\"[OK] Found {len(pref_cols)} connectivity columns with prefix '{conn_prefix}'.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Core: single CV run (supports either real y or permuted y)\n",
    "# -------------------------\n",
    "def cv_auc_foldwise_augmented(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    splits,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    return_debug: bool = False\n",
    "):\n",
    "    aucs = []\n",
    "    picked_sets = []\n",
    "    edge_use_counter = Counter()\n",
    "    missing_edges_total = 0\n",
    "\n",
    "    for tr, te in splits:\n",
    "        Xtr, Xte = Xbase.iloc[tr], Xbase.iloc[te]\n",
    "        ytr, yte = y[tr], y[te]\n",
    "\n",
    "        # 1) pick top ICs from TRAIN only (Ln-only)\n",
    "        base_model = fixed_pipe(C=C_base, penalty=penalty)\n",
    "        base_model.fit(Xtr, ytr)\n",
    "        w = base_model.named_steps[\"clf\"].coef_.ravel()\n",
    "        scores = ic_group_importance_from_coef(Xtr.columns, w)\n",
    "        top = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)[:top_m]\n",
    "        top_ics = [ic for ic, _ in top]\n",
    "        picked_sets.append(tuple(top_ics))\n",
    "\n",
    "        # 2) add connectivity edges among those ICs\n",
    "        wanted_cols = connectivity_cols_for_ics(top_ics, prefix=conn_prefix)\n",
    "        cols = [c for c in wanted_cols if c in conn.columns]\n",
    "        missing_edges_total += (len(wanted_cols) - len(cols))\n",
    "        edge_use_counter.update(cols)\n",
    "\n",
    "        Xtr_aug = pd.concat([Xtr, conn.iloc[tr][cols]], axis=1)\n",
    "        Xte_aug = pd.concat([Xte, conn.iloc[te][cols]], axis=1)\n",
    "\n",
    "        # 3) fit final model and score AUC\n",
    "        final_model = fixed_pipe(C=C_final, penalty=penalty)\n",
    "        final_model.fit(Xtr_aug, ytr)\n",
    "        p = final_model.predict_proba(Xte_aug)[:, 1]\n",
    "\n",
    "        # If test fold has only one class, AUC undefined -> skip fold\n",
    "        if len(np.unique(yte)) < 2:\n",
    "            continue\n",
    "\n",
    "        aucs.append(roc_auc_score(yte, p))\n",
    "\n",
    "    auc_mean = float(np.mean(aucs))\n",
    "\n",
    "    if not return_debug:\n",
    "        return auc_mean\n",
    "\n",
    "    n_folds = len(aucs)\n",
    "    return {\n",
    "        \"auc_mean\": auc_mean,\n",
    "        \"auc_sd\": float(np.std(aucs)),\n",
    "        \"n_folds\": int(n_folds),\n",
    "        \"most_common_ic_sets\": Counter(picked_sets).most_common(10),\n",
    "        \"most_used_edges\": edge_use_counter.most_common(15),\n",
    "        \"avg_missing_edges_per_fold\": float(missing_edges_total / n_folds) if n_folds > 0 else float(\"nan\")\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Repeated CV summary\n",
    "# -------------------------\n",
    "def repeated_cv_summary_augmented(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    n_splits: int = 5,\n",
    "    n_repeats: int = 200,\n",
    "    seed: int = 42\n",
    "):\n",
    "    sanity_check_inputs(Xbase, conn, y, conn_prefix=conn_prefix)\n",
    "    expected_edges = top_m * (top_m - 1) // 2\n",
    "    print(f\"[INFO] top_m={top_m} -> expected edges per fold = C({top_m},2) = {expected_edges}\")\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    splits = list(rskf.split(Xbase, y))\n",
    "\n",
    "    out = cv_auc_foldwise_augmented(\n",
    "        Xbase, conn, y, splits,\n",
    "        conn_prefix=conn_prefix,\n",
    "        top_m=top_m,\n",
    "        C_base=C_base,\n",
    "        C_final=C_final,\n",
    "        penalty=penalty,\n",
    "        return_debug=True\n",
    "    )\n",
    "\n",
    "    print(f\"[INFO] Avg missing edges per fold: {out['avg_missing_edges_per_fold']:.3f} (should be ~0)\")\n",
    "    out[\"top_m\"] = int(top_m)\n",
    "    out[\"expected_edges_per_fold\"] = int(expected_edges)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Manual permutation test (publication-friendly)\n",
    "# -------------------------\n",
    "def permutation_test_augmented_auc(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    n_splits: int = 5,\n",
    "    n_perm: int = 2000,\n",
    "    seed: int = 0,\n",
    "    verbose_every: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      observed_auc, p_value, perm_aucs (array)\n",
    "    p-value computed as (1 + #perm >= obs) / (1 + n_perm)\n",
    "    \"\"\"\n",
    "    sanity_check_inputs(Xbase, conn, y, conn_prefix=conn_prefix)\n",
    "\n",
    "    # Fix CV splits once (important!)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    splits = list(cv.split(Xbase, y))\n",
    "\n",
    "    # Observed score\n",
    "    obs = cv_auc_foldwise_augmented(\n",
    "        Xbase, conn, y, splits,\n",
    "        conn_prefix=conn_prefix,\n",
    "        top_m=top_m,\n",
    "        C_base=C_base,\n",
    "        C_final=C_final,\n",
    "        penalty=penalty,\n",
    "        return_debug=False\n",
    "    )\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm_scores = np.empty(n_perm, dtype=float)\n",
    "\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y)  # preserves class counts automatically\n",
    "        perm_scores[i] = cv_auc_foldwise_augmented(\n",
    "            Xbase, conn, y_perm, splits,\n",
    "            conn_prefix=conn_prefix,\n",
    "            top_m=top_m,\n",
    "            C_base=C_base,\n",
    "            C_final=C_final,\n",
    "            penalty=penalty,\n",
    "            return_debug=False\n",
    "        )\n",
    "        if verbose_every and (i + 1) % verbose_every == 0:\n",
    "            print(f\"[perm] {i+1}/{n_perm} done...\")\n",
    "\n",
    "    p = (1.0 + np.sum(perm_scores >= obs)) / (1.0 + n_perm)\n",
    "    return float(obs), float(p), perm_scores\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# RUN (Ln-only + Ln connectivity)\n",
    "# -------------------------\n",
    "ROOT = Path(r\"/Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA\")\n",
    "K = 20\n",
    "\n",
    "LABELS_CSV = ROOT / \"proficiency_labels.csv\"\n",
    "FEAT_STATIC = ROOT / f\"features_static_nonZ_K{K}.csv\"\n",
    "FEAT_LN_CONN = ROOT / f\"features_ln_conn_pearsonZ_K{K}.csv\"\n",
    "\n",
    "labels = pd.read_csv(LABELS_CSV).set_index(\"subject\")\n",
    "labels[\"group\"] = labels[\"group\"].str.lower().str.strip()\n",
    "labels[\"y\"] = (labels[\"group\"] == \"advanced\").astype(int)\n",
    "\n",
    "Xstatic = pd.read_csv(FEAT_STATIC).set_index(\"subject\")\n",
    "connLn = pd.read_csv(FEAT_LN_CONN).set_index(\"subject\")\n",
    "\n",
    "df = Xstatic.join(labels[[\"y\"]], how=\"inner\")\n",
    "X_Ln = df.filter(regex=r\"^Ln_\").copy()\n",
    "\n",
    "# Align (exact index match)\n",
    "common = X_Ln.index.intersection(connLn.index)\n",
    "X_base = X_Ln.loc[common].copy()\n",
    "y_base = labels.loc[common, \"y\"].to_numpy()\n",
    "connLn = connLn.loc[common].copy()\n",
    "connLn = connLn.loc[X_base.index]\n",
    "\n",
    "print(\"\\n=== Repeated CV summary (sanity-checked): Ln-only base + top-IC Ln connectivity ===\")\n",
    "aug_ln = repeated_cv_summary_augmented(\n",
    "    Xbase=X_base,\n",
    "    conn=connLn,\n",
    "    y=y_base,\n",
    "    conn_prefix=\"Ln_zcorr\",\n",
    "    top_m=5,\n",
    "    C_base=1.0,\n",
    "    C_final=1.0,\n",
    "    penalty=\"l2\",\n",
    "    n_splits=5,\n",
    "    n_repeats=200,\n",
    "    seed=42\n",
    ")\n",
    "print(aug_ln)\n",
    "\n",
    "print(\"\\n=== Manual permutation test (leakage-safe) for augmented Ln model ===\")\n",
    "obs_auc, pval, perm_aucs = permutation_test_augmented_auc(\n",
    "    Xbase=X_base,\n",
    "    conn=connLn,\n",
    "    y=y_base,\n",
    "    conn_prefix=\"Ln_zcorr\",\n",
    "    top_m=5,\n",
    "    C_base=1.0,\n",
    "    C_final=1.0,\n",
    "    penalty=\"l2\",\n",
    "    n_splits=5,\n",
    "    n_perm=2000,     # start 500 if you want quick; 2000 for final\n",
    "    seed=0,\n",
    "    verbose_every=200\n",
    ")\n",
    "print(\"Observed 5-fold AUC:\", obs_auc)\n",
    "print(\"Permutation p-value:\", pval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# PART 3 — LN-ONLY + TOP-IC LN CONNECTIVITY (LEAKAGE-SAFE)\n",
    "# + Manual permutation test (publication-friendly; avoids sklearn tag issues)\n",
    "# Mirrors your PCA Part 3, but uses IC naming.\n",
    "# =========================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Basic model builder\n",
    "# -------------------------\n",
    "def fixed_pipe(C=1.0, penalty=\"l2\"):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=5000,\n",
    "            C=C,\n",
    "            penalty=penalty\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "def ic_group_importance_from_coef(feature_names, coef):\n",
    "    \"\"\"Sum |coef| by IC index extracted from names like Ln_IC07_...\"\"\"\n",
    "    ic_re = re.compile(r\"IC(\\d{2})\")\n",
    "    scores = {}\n",
    "    for name, w in zip(feature_names, coef):\n",
    "        m = ic_re.search(name)\n",
    "        if not m:\n",
    "            continue\n",
    "        ic = int(m.group(1))\n",
    "        scores[ic] = scores.get(ic, 0.0) + abs(float(w))\n",
    "    return scores\n",
    "\n",
    "def connectivity_cols_for_ics(ics, prefix=\"Ln_zcorr\"):\n",
    "    ics = sorted(ics)\n",
    "    cols = []\n",
    "    for i in range(len(ics)):\n",
    "        for j in range(i + 1, len(ics)):\n",
    "            a, b = ics[i], ics[j]\n",
    "            cols.append(f\"{prefix}_IC{a:02d}_IC{b:02d}\")\n",
    "    return cols\n",
    "\n",
    "def sanity_check_inputs(Xbase: pd.DataFrame, conn: pd.DataFrame, y: np.ndarray, conn_prefix: str):\n",
    "    assert isinstance(Xbase, pd.DataFrame) and isinstance(conn, pd.DataFrame)\n",
    "    assert len(Xbase) == len(y), \"Xbase and y length mismatch\"\n",
    "    assert Xbase.index.equals(conn.index), \"Xbase and conn indices must match exactly\"\n",
    "    assert set(np.unique(y)).issubset({0, 1}), \"y must be binary 0/1\"\n",
    "\n",
    "    pref_cols = [c for c in conn.columns if c.startswith(conn_prefix + \"_IC\")]\n",
    "    if len(pref_cols) == 0:\n",
    "        raise ValueError(f\"No connectivity columns found with prefix='{conn_prefix}'.\")\n",
    "    print(f\"[OK] Found {len(pref_cols)} connectivity columns with prefix '{conn_prefix}'.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Core: single CV run (supports either real y or permuted y)\n",
    "# -------------------------\n",
    "def cv_auc_foldwise_augmented(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    splits,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    return_debug: bool = False\n",
    "):\n",
    "    aucs = []\n",
    "    picked_sets = []\n",
    "    edge_use_counter = Counter()\n",
    "    missing_edges_total = 0\n",
    "\n",
    "    for tr, te in splits:\n",
    "        Xtr, Xte = Xbase.iloc[tr], Xbase.iloc[te]\n",
    "        ytr, yte = y[tr], y[te]\n",
    "\n",
    "        # 1) pick top ICs from TRAIN only (Ln-only)\n",
    "        base_model = fixed_pipe(C=C_base, penalty=penalty)\n",
    "        base_model.fit(Xtr, ytr)\n",
    "        w = base_model.named_steps[\"clf\"].coef_.ravel()\n",
    "        scores = ic_group_importance_from_coef(Xtr.columns, w)\n",
    "        top = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)[:top_m]\n",
    "        top_ics = [ic for ic, _ in top]\n",
    "        picked_sets.append(tuple(top_ics))\n",
    "\n",
    "        # 2) add connectivity edges among those ICs\n",
    "        wanted_cols = connectivity_cols_for_ics(top_ics, prefix=conn_prefix)\n",
    "        cols = [c for c in wanted_cols if c in conn.columns]\n",
    "        missing_edges_total += (len(wanted_cols) - len(cols))\n",
    "        edge_use_counter.update(cols)\n",
    "\n",
    "        Xtr_aug = pd.concat([Xtr, conn.iloc[tr][cols]], axis=1)\n",
    "        Xte_aug = pd.concat([Xte, conn.iloc[te][cols]], axis=1)\n",
    "\n",
    "        # 3) fit final model and score AUC\n",
    "        final_model = fixed_pipe(C=C_final, penalty=penalty)\n",
    "        final_model.fit(Xtr_aug, ytr)\n",
    "        p = final_model.predict_proba(Xte_aug)[:, 1]\n",
    "\n",
    "        # If test fold has only one class, AUC undefined -> skip fold\n",
    "        if len(np.unique(yte)) < 2:\n",
    "            continue\n",
    "\n",
    "        aucs.append(roc_auc_score(yte, p))\n",
    "\n",
    "    auc_mean = float(np.mean(aucs))\n",
    "\n",
    "    if not return_debug:\n",
    "        return auc_mean\n",
    "\n",
    "    n_folds = len(aucs)\n",
    "    return {\n",
    "        \"auc_mean\": auc_mean,\n",
    "        \"auc_sd\": float(np.std(aucs)),\n",
    "        \"n_folds\": int(n_folds),\n",
    "        \"most_common_ic_sets\": Counter(picked_sets).most_common(10),\n",
    "        \"most_used_edges\": edge_use_counter.most_common(15),\n",
    "        \"avg_missing_edges_per_fold\": float(missing_edges_total / n_folds) if n_folds > 0 else float(\"nan\")\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Repeated CV summary\n",
    "# -------------------------\n",
    "def repeated_cv_summary_augmented(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    n_splits: int = 5,\n",
    "    n_repeats: int = 200,\n",
    "    seed: int = 42\n",
    "):\n",
    "    sanity_check_inputs(Xbase, conn, y, conn_prefix=conn_prefix)\n",
    "    expected_edges = top_m * (top_m - 1) // 2\n",
    "    print(f\"[INFO] top_m={top_m} -> expected edges per fold = C({top_m},2) = {expected_edges}\")\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    splits = list(rskf.split(Xbase, y))\n",
    "\n",
    "    out = cv_auc_foldwise_augmented(\n",
    "        Xbase, conn, y, splits,\n",
    "        conn_prefix=conn_prefix,\n",
    "        top_m=top_m,\n",
    "        C_base=C_base,\n",
    "        C_final=C_final,\n",
    "        penalty=penalty,\n",
    "        return_debug=True\n",
    "    )\n",
    "\n",
    "    print(f\"[INFO] Avg missing edges per fold: {out['avg_missing_edges_per_fold']:.3f} (should be ~0)\")\n",
    "    out[\"top_m\"] = int(top_m)\n",
    "    out[\"expected_edges_per_fold\"] = int(expected_edges)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Manual permutation test (publication-friendly)\n",
    "# -------------------------\n",
    "def permutation_test_augmented_auc(\n",
    "    Xbase: pd.DataFrame,\n",
    "    conn: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    conn_prefix: str = \"Ln_zcorr\",\n",
    "    top_m: int = 5,\n",
    "    C_base: float = 1.0,\n",
    "    C_final: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    n_splits: int = 5,\n",
    "    n_perm: int = 2000,\n",
    "    seed: int = 0,\n",
    "    verbose_every: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      observed_auc, p_value, perm_aucs (array)\n",
    "    p-value computed as (1 + #perm >= obs) / (1 + n_perm)\n",
    "    \"\"\"\n",
    "    sanity_check_inputs(Xbase, conn, y, conn_prefix=conn_prefix)\n",
    "\n",
    "    # Fix CV splits once (important!)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    splits = list(cv.split(Xbase, y))\n",
    "\n",
    "    # Observed score\n",
    "    obs = cv_auc_foldwise_augmented(\n",
    "        Xbase, conn, y, splits,\n",
    "        conn_prefix=conn_prefix,\n",
    "        top_m=top_m,\n",
    "        C_base=C_base,\n",
    "        C_final=C_final,\n",
    "        penalty=penalty,\n",
    "        return_debug=False\n",
    "    )\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm_scores = np.empty(n_perm, dtype=float)\n",
    "\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y)  # preserves class counts automatically\n",
    "        perm_scores[i] = cv_auc_foldwise_augmented(\n",
    "            Xbase, conn, y_perm, splits,\n",
    "            conn_prefix=conn_prefix,\n",
    "            top_m=top_m,\n",
    "            C_base=C_base,\n",
    "            C_final=C_final,\n",
    "            penalty=penalty,\n",
    "            return_debug=False\n",
    "        )\n",
    "        if verbose_every and (i + 1) % verbose_every == 0:\n",
    "            print(f\"[perm] {i+1}/{n_perm} done...\")\n",
    "\n",
    "    p = (1.0 + np.sum(perm_scores >= obs)) / (1.0 + n_perm)\n",
    "    return float(obs), float(p), perm_scores\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# RUN (Ln-only + Ln connectivity)\n",
    "# -------------------------\n",
    "ROOT = Path(r\"/Users/onilarasanjala/Desktop/TSeme/CogNeuSci/CodeData/NewICA\")\n",
    "K = 20\n",
    "\n",
    "LABELS_CSV = ROOT / \"proficiency_labels.csv\"\n",
    "FEAT_STATIC = ROOT / f\"features_static_nonZ_K{K}.csv\"\n",
    "FEAT_LN_CONN = ROOT / f\"features_ln_conn_pearsonZ_K{K}.csv\"\n",
    "\n",
    "labels = pd.read_csv(LABELS_CSV).set_index(\"subject\")\n",
    "labels[\"group\"] = labels[\"group\"].str.lower().str.strip()\n",
    "labels[\"y\"] = (labels[\"group\"] == \"advanced\").astype(int)\n",
    "\n",
    "Xstatic = pd.read_csv(FEAT_STATIC).set_index(\"subject\")\n",
    "connLn = pd.read_csv(FEAT_LN_CONN).set_index(\"subject\")\n",
    "\n",
    "df = Xstatic.join(labels[[\"y\"]], how=\"inner\")\n",
    "X_Ln = df.filter(regex=r\"^Ln_\").copy()\n",
    "\n",
    "# Align (exact index match)\n",
    "common = X_Ln.index.intersection(connLn.index)\n",
    "X_base = X_Ln.loc[common].copy()\n",
    "y_base = labels.loc[common, \"y\"].to_numpy()\n",
    "connLn = connLn.loc[common].copy()\n",
    "connLn = connLn.loc[X_base.index]\n",
    "\n",
    "print(\"\\n=== Repeated CV summary (sanity-checked): Ln-only base + top-IC Ln connectivity ===\")\n",
    "aug_ln = repeated_cv_summary_augmented(\n",
    "    Xbase=X_base,\n",
    "    conn=connLn,\n",
    "    y=y_base,\n",
    "    conn_prefix=\"Ln_zcorr\",\n",
    "    top_m=5,\n",
    "    C_base=1.0,\n",
    "    C_final=1.0,\n",
    "    penalty=\"l2\",\n",
    "    n_splits=5,\n",
    "    n_repeats=200,\n",
    "    seed=42\n",
    ")\n",
    "print(aug_ln)\n",
    "\n",
    "print(\"\\n=== Manual permutation test (leakage-safe) for augmented Ln model ===\")\n",
    "obs_auc, pval, perm_aucs = permutation_test_augmented_auc(\n",
    "    Xbase=X_base,\n",
    "    conn=connLn,\n",
    "    y=y_base,\n",
    "    conn_prefix=\"Ln_zcorr\",\n",
    "    top_m=5,\n",
    "    C_base=1.0,\n",
    "    C_final=1.0,\n",
    "    penalty=\"l2\",\n",
    "    n_splits=5,\n",
    "    n_perm=2000,     # start 500 if you want quick; 2000 for final\n",
    "    seed=0,\n",
    "    verbose_every=200\n",
    ")\n",
    "print(\"Observed 5-fold AUC:\", obs_auc)\n",
    "print(\"Permutation p-value:\", pval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
